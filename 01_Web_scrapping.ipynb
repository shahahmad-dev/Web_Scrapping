{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **`Web scrapping`**"
      ],
      "metadata": {
        "id": "1NDs54Fu-hj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.wisden.com/series/psl-2026/cricket-news/psl-2026-auction-full-list-of-players-with-base-price-for-pakistan-super-league-auction\"\n",
        "\n",
        "soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
        "\n",
        "table = soup.find(\"table\")   # sirf first table le lo\n",
        "rows = table.find_all(\"tr\")[1:]\n",
        "\n",
        "data = [\n",
        "    [col.text.strip() for col in row.find_all([\"td\",\"th\"])]\n",
        "    for row in rows\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n",
        "\n",
        "df.to_csv(\"psl2026.csv\", index=False, header=True)"
      ],
      "metadata": {
        "id": "omCQk_rcEsOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZthgcOjGc8p"
      },
      "source": [
        "# rename the columns\n",
        "# Please provide the list of desired column names in place of 'col1', 'col2', etc.\n",
        "df.columns = ['Player_ID', 'Player_Name', 'Nationality', 'Role', 'Batting_Style', 'Bowling_Style', 'Base_Price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HZkOc4_xHfnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.geeksforgeeks.org/\"\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Article links + titles\n",
        "articles = soup.find_all(\"a\")\n",
        "\n",
        "data = []\n",
        "\n",
        "for a in articles:\n",
        "    title = a.text.strip()\n",
        "    link = a.get(\"href\")\n",
        "\n",
        "    if title and link and link.startswith(\"https\"):\n",
        "        data.append([title, link])\n",
        "\n",
        "# DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Title\", \"Link\"])\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Save CSV\n",
        "df.to_csv(\"gfg_articles.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "2gRbe7_NHhKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aT0ssQBWJ1sl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}